## 神经计算前沿调研

目前计算机界唯有DeepMind的研究与神经科学交叉较多，其也拥有相当多的神经科学家，包括其创始人。计算机界在神经计算的最前沿进展我认为可以完全参考他们的研究。而计算神经科学界，其内容涉猎太多，一时不好找到切入点，目前个人感觉需要更多的文献积累。以下我认为重点的文章已用加粗标记。

DeepMind近年在脑启发人工智能算法设计上的重要研究工作我整理如下：

- **Neuroscience-Inspired Artificial Intelligence**, 2017-7

  特别完美的一篇对神经科学与人工智能现状的一篇综述。文章认为更好地理解生物大脑可以在构建智能机器中发挥至关重要的作用，来自神经科学的想法将变得越来越不可或缺。

  文章关键内容我认为有以下几点：

  - PDP方法启发的并行分布式算法设计
  - 灵长类视觉系统启发的CNN中的非线性转化、分裂归一化、最大值池化
  - 受动物实验启发的时间差分二阶调节强化学习算法
  - 重复记忆导致直接的动作价值强化，不重复的高回报记忆通过经验重放学习
  - 弹性权重固结（EWC）算法解决深层网络中持续学习的挑战
  - 预测与回放
  - 反传算法的近似：连续Hopfield网络等基于能量的网络、分层自编码器（预测编码、本地更新、Hebbian机制）、分层监督网络

- **The hippocampus as a predictive map**, 2016-12

  文章介绍了预测表示形式是最有利于最大化未来奖励的空间表征。第一次奖励的获得对于动物而言可能需要非常久的时间，一种是建立环境模型来模拟后继状态的方法，一种是无模型的计算价值函数方法，还有一种，就是本文提出的学习预测。

  个人理解这三种预测的区别是：第一种是构建一个巨大的模型，输入任何状态都能得到其未来所有状态及其累积奖励的估计，第二种是构建一个模型（函数映射），输入状态得出估计的状态价值，第三种是输入一个状态，输出其在动作空间下估计的后继状态。

- **Prefrontal cortex as a meta-reinforcement learning system**, 2018-4

  文章介绍了由多巴胺引导的学习以及由前额叶皮层引导的学习的结合，多巴胺奖励直接预测误差信号，前额叶皮层构建模型预测产生基于模型的预测误差学习。

- **Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures**, 2018-7

  文章主要探讨了BP算法的两种变体目标传播（TP）和反馈对齐（FA）及它们的变体在MNIST、CIFAR以及ImageNet上的表现。作者首先对BP算法在生理学上的对应证据表示质疑，并依据神经科学的启发式思想研究了BP算法更近似于脑的两种变体TP和FA的效果，并得出两种方法的效果在复杂数据集上明显较差的结论。

  值得注意的是，作者指出这是他们扩大脑启发模型的第一批结果，且目的是为之后的研究设立基线，考虑文章公布的时间为今年的7月，可以合理地猜想DeepMind有意向从这里开始研究神经科学指导的智能机器的设计。

- Representation Learning with Contrastive Predictive Coding, 2018-7

  这篇文章偏向传统方法，主要是通过预测编码提升无监督学习的效果。

- Neural scene representation and rendering, 2018-6

  DeepMind创始人的一篇文章，主要是为神经网络加入推理视觉不可见部分的能力，设计上类似于生成对抗网络。

- Memory-based Parameter Adaptation, 2018-2

  通过记忆来指导神经网络权重的更新，目标是为了提高学习率，使网络能更快地学习。

- Dorsal hippocampus contributes to model-based planning, 2017-7

  纯神经科学的一篇文章，用于证明海马体与智能规划的关系。

- Hybrid computing using a neural network with dynamic external memory, 2016-10

  文章提出了著名的可微分神经计算机，为神经网络提供了外部存储。

另外有一些非DeepMind发表的论文，可以作为一定参考：

- Cognitive Intelligence: Deep Learning, Thinking, and Reasoning by Brain-Inspired Systems, 2016-12

  斯坦福大学认知信息学组对认知信息学以及认知计算的一份综述。

- Cognitive Artificial Intelligence: Brain-Inspired Intelligent Computation in Artificial Intelligence, 2017-7

  本文提出了一种知识增长系统，使算法能不断学习和更新其记忆的知识。

- Time-Causal and Time-Recursive Spatio-Temporal Receptive Fields, 2015-4

  文章对传统的V1皮层的数学建模提出了一些修正。

- The Brain Circuit Challenge, 2017-8

  Science的一篇带科普性质的文章，介绍了目前学界在大脑回路连接方式的一些研究，可以作为设计网络的一些参考，不过个人认为简单神经回路只能作为参考，智能的关键还是在更高层次的感知上。

- **Deep learning in the visual cortex**, Thomas Serre, Brown University

  这是一份关于视觉皮层处理视觉信息的一份PPT，对视觉信息的具体处理讲解得十分清楚。

目前以实验室为平台进行更通用人工智能研究的话，我认为可以做关于基于时间差分算法的强化学习算法、预测模块加入、环境模型构建等方向的研究，放开一些的话可以做弹性权重固结、反传算法变体等方向的研究。
